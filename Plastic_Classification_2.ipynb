{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n",
      "Augmenting training data...\n",
      "Skipping invalid image file: output_dataset\\train\\HDPE\\image197.avif due to error: cannot identify image file 'output_dataset\\\\train\\\\HDPE\\\\image197.avif'\n",
      "Skipping invalid image file: output_dataset\\train\\LDPE\\image115.avif due to error: cannot identify image file 'output_dataset\\\\train\\\\LDPE\\\\image115.avif'\n",
      "Skipping invalid image file: output_dataset\\train\\PET\\image140.avif due to error: cannot identify image file 'output_dataset\\\\train\\\\PET\\\\image140.avif'\n",
      "Skipping invalid image file: output_dataset\\train\\PP\\mountain-discarded-plastic-garbage-bottles-generative-ai_170984-12661.avif due to error: cannot identify image file 'output_dataset\\\\train\\\\PP\\\\mountain-discarded-plastic-garbage-bottles-generative-ai_170984-12661.avif'\n",
      "Skipping invalid image file: output_dataset\\train\\PS\\CHAPTER-I INTRODUCTION TO DB CONCEPTS.pdf due to error: cannot identify image file 'output_dataset\\\\train\\\\PS\\\\CHAPTER-I INTRODUCTION TO DB CONCEPTS.pdf'\n",
      "Skipping invalid image file: output_dataset\\train\\PVC\\image74.avif due to error: cannot identify image file 'output_dataset\\\\train\\\\PVC\\\\image74.avif'\n",
      "Normalizing images...\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\HDPE\\image197.avif\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\LDPE\\image115.avif\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\PET\\image140.avif\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\PP\\mountain-discarded-plastic-garbage-bottles-generative-ai_170984-12661.avif\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\PS\\CHAPTER-I INTRODUCTION TO DB CONCEPTS.pdf\n",
      "Skipping invalid or unreadable image: output_dataset\\train\\PVC\\image74.avif\n",
      "Skipping invalid or unreadable image: output_dataset\\test\\PP\\mountain-discarded-plastic-garbage-bottles-generative-ai_170984-12661 (1).avif\n",
      "Skipping invalid or unreadable image: output_dataset\\test\\PVC\\image77.avif\n",
      "Dataset preparation complete. Training and testing datasets are ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import PIL\n",
    "from PIL import Image, UnidentifiedImageError \n",
    "\n",
    "# Define paths\n",
    "original_dataset_dir = 'Dataset'  # Folder with all images categorized by subfolders (classes)\n",
    "output_base_dir = 'output_dataset'\n",
    "train_dir = os.path.join(output_base_dir, 'train')\n",
    "test_dir = os.path.join(output_base_dir, 'test')\n",
    "\n",
    "# Define parameters\n",
    "test_size = 0.2  # Proportion of data to be used for testing\n",
    "IMG_SIZE = (224, 224)  # Resize images for consistency\n",
    "AUGMENTATIONS = 10  # Number of augmented images per original image\n",
    "\n",
    "# Create output directories\n",
    "def create_dir_structure(base_dir, classes):\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(base_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "def split_dataset(base_dir, output_train_dir, output_test_dir, test_ratio):\n",
    "    classes = os.listdir(base_dir)\n",
    "    create_dir_structure(output_train_dir, classes)\n",
    "    create_dir_structure(output_test_dir, classes)\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(base_dir, class_name)\n",
    "        images = os.listdir(class_dir)\n",
    "        train_images, test_images = train_test_split(images, test_size=test_ratio, random_state=42)\n",
    "\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(class_dir, img), os.path.join(output_train_dir, class_name))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(class_dir, img), os.path.join(output_test_dir, class_name))\n",
    "\n",
    "# Augment training data\n",
    "def augment_images(input_dir, output_dir, augmentations):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        \n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            \n",
    "            # Check if the file is a valid image before processing\n",
    "            try:\n",
    "                Image.open(img_path).verify() \n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Skipping invalid image file: {img_path} due to error: {e}\")\n",
    "                continue # Skip to the next image\n",
    "\n",
    "            img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1, save_to_dir=output_class_dir, \n",
    "                                      save_prefix='aug', save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i >= augmentations:\n",
    "                    break  # Stop after creating `augmentations` images\n",
    "\n",
    "\n",
    "# Additional Preprocessing (Normalization)\n",
    "def preprocess_images(input_dir):\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255)  # Normalize pixel values to [0, 1]\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_dir = os.path.join(input_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                # Attempt to open and verify the image\n",
    "                img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Skipping invalid or unreadable image: {img_path}\")\n",
    "                # Optional: Remove the problematic file if you want to clean up the dataset\n",
    "                os.remove(img_path) \n",
    "                continue # Move on to the next image\n",
    "\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize\n",
    "            # Save the preprocessed image back (Optional)\n",
    "            array_to_img(img_array).save(img_path)\n",
    "\n",
    "# Main workflow\n",
    "print(\"Splitting dataset...\")\n",
    "split_dataset(original_dataset_dir, train_dir, test_dir, test_size)\n",
    "\n",
    "print(\"Augmenting training data...\")\n",
    "augment_images(train_dir, train_dir, AUGMENTATIONS)\n",
    "\n",
    "print(\"Normalizing images...\")\n",
    "preprocess_images(train_dir)\n",
    "preprocess_images(test_dir)\n",
    "\n",
    "print(\"Dataset preparation complete. Training and testing datasets are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8588 images belonging to 6 classes.\n",
      "Found 195 images belonging to 6 classes.\n",
      "Training VGG16 model...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3757 - loss: 1.6207\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54872, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 3s/step - accuracy: 0.3760 - loss: 1.6199 - val_accuracy: 0.5487 - val_loss: 1.2104\n",
      "Epoch 2/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6262 - loss: 1.0059\n",
      "Epoch 2: val_accuracy improved from 0.54872 to 0.61026, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 2s/step - accuracy: 0.6263 - loss: 1.0058 - val_accuracy: 0.6103 - val_loss: 1.1422\n",
      "Epoch 3/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7204 - loss: 0.7989\n",
      "Epoch 3: val_accuracy improved from 0.61026 to 0.64103, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 2s/step - accuracy: 0.7205 - loss: 0.7988 - val_accuracy: 0.6410 - val_loss: 1.1017\n",
      "Epoch 4/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7850 - loss: 0.6272\n",
      "Epoch 4: val_accuracy did not improve from 0.64103\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 2s/step - accuracy: 0.7850 - loss: 0.6272 - val_accuracy: 0.6205 - val_loss: 1.1416\n",
      "Epoch 5/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8349 - loss: 0.5082\n",
      "Epoch 5: val_accuracy did not improve from 0.64103\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 2s/step - accuracy: 0.8349 - loss: 0.5082 - val_accuracy: 0.6154 - val_loss: 1.1909\n",
      "Epoch 6/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8679 - loss: 0.4310\n",
      "Epoch 6: val_accuracy did not improve from 0.64103\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 2s/step - accuracy: 0.8679 - loss: 0.4309 - val_accuracy: 0.6205 - val_loss: 1.1991\n",
      "Epoch 7/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8937 - loss: 0.3550\n",
      "Epoch 7: val_accuracy did not improve from 0.64103\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 2s/step - accuracy: 0.8937 - loss: 0.3550 - val_accuracy: 0.6256 - val_loss: 1.2418\n",
      "Epoch 8/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9149 - loss: 0.2964\n",
      "Epoch 8: val_accuracy improved from 0.64103 to 0.65641, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 2s/step - accuracy: 0.9149 - loss: 0.2964 - val_accuracy: 0.6564 - val_loss: 1.2292\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet50 model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2452 - loss: 1.9531\n",
      "Epoch 1: val_accuracy did not improve from 0.65641\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 1s/step - accuracy: 0.2453 - loss: 1.9525 - val_accuracy: 0.2615 - val_loss: 1.7113\n",
      "Epoch 2/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2692 - loss: 1.7246\n",
      "Epoch 2: val_accuracy did not improve from 0.65641\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 1s/step - accuracy: 0.2692 - loss: 1.7246 - val_accuracy: 0.3231 - val_loss: 1.6930\n",
      "Epoch 3/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2948 - loss: 1.7078\n",
      "Epoch 3: val_accuracy did not improve from 0.65641\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 1s/step - accuracy: 0.2948 - loss: 1.7078 - val_accuracy: 0.3641 - val_loss: 1.6705\n",
      "Epoch 4/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2958 - loss: 1.6971\n",
      "Epoch 4: val_accuracy did not improve from 0.65641\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 1s/step - accuracy: 0.2958 - loss: 1.6971 - val_accuracy: 0.3692 - val_loss: 1.6665\n",
      "Epoch 5/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2920 - loss: 1.6986\n",
      "Epoch 5: val_accuracy did not improve from 0.65641\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 1s/step - accuracy: 0.2920 - loss: 1.6986 - val_accuracy: 0.3590 - val_loss: 1.6550\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete. Models saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'output_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 20\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# VGG16 Model\n",
    "def create_vgg16_model():\n",
    "    vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = Flatten()(vgg16_base.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=vgg16_base.input, outputs=output)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in vgg16_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ResNet50 Model\n",
    "def create_resnet50_model():\n",
    "    resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = Flatten()(resnet50_base.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=resnet50_base.input, outputs=output)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in resnet50_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Train VGG16\n",
    "print(\"Training VGG16 model...\")\n",
    "vgg16_model = create_vgg16_model()\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Save VGG16 model\n",
    "vgg16_model.save(\"vgg16_final_model.h5\")\n",
    "\n",
    "# Train ResNet50\n",
    "print(\"Training ResNet50 model...\")\n",
    "resnet50_model = create_resnet50_model()\n",
    "resnet50_history = resnet50_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Save ResNet50 model\n",
    "resnet50_model.save(\"resnet50_final_model.h5\")\n",
    "\n",
    "print(\"Model training complete. Models saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HDPE       0.26      0.62      0.36        52\n",
      "        LDPE       0.00      0.00      0.00        26\n",
      "         PET       0.21      0.20      0.20        46\n",
      "          PP       0.22      0.21      0.22        28\n",
      "          PS       0.00      0.00      0.00        22\n",
      "         PVC       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.24       195\n",
      "   macro avg       0.11      0.17      0.13       195\n",
      "weighted avg       0.15      0.24      0.18       195\n",
      "\n",
      "Model Accuracy: 24.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model(\"resnet50_final_model.h5\")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HDPE       0.36      0.38      0.37        52\n",
      "        LDPE       0.20      0.19      0.20        26\n",
      "         PET       0.28      0.28      0.28        46\n",
      "          PP       0.11      0.11      0.11        28\n",
      "          PS       0.09      0.09      0.09        22\n",
      "         PVC       0.05      0.05      0.05        21\n",
      "\n",
      "    accuracy                           0.23       195\n",
      "   macro avg       0.18      0.18      0.18       195\n",
      "weighted avg       0.22      0.23      0.22       195\n",
      "\n",
      "Model Accuracy: 22.56%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model(\"New Folder/vgg16_final_model.h5\")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8588 images belonging to 6 classes.\n",
      "Found 195 images belonging to 6 classes.\n",
      "Training ResNet50 model...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2349 - loss: 1.9378\n",
      "Epoch 1: val_accuracy improved from -inf to 0.26154, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 2s/step - accuracy: 0.2350 - loss: 1.9373 - val_accuracy: 0.2615 - val_loss: 1.6849\n",
      "Epoch 2/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2641 - loss: 1.7126\n",
      "Epoch 2: val_accuracy improved from 0.26154 to 0.34359, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 1s/step - accuracy: 0.2642 - loss: 1.7126 - val_accuracy: 0.3436 - val_loss: 1.6689\n",
      "Epoch 3/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2875 - loss: 1.6909\n",
      "Epoch 3: val_accuracy did not improve from 0.34359\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 1s/step - accuracy: 0.2875 - loss: 1.6909 - val_accuracy: 0.3333 - val_loss: 1.6985\n",
      "Epoch 4/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2742 - loss: 1.6842\n",
      "Epoch 4: val_accuracy did not improve from 0.34359\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.2742 - loss: 1.6842 - val_accuracy: 0.3026 - val_loss: 1.6745\n",
      "Epoch 5/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2961 - loss: 1.6784\n",
      "Epoch 5: val_accuracy did not improve from 0.34359\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.2961 - loss: 1.6784 - val_accuracy: 0.3077 - val_loss: 1.6743\n",
      "Epoch 6/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3112 - loss: 1.6726\n",
      "Epoch 6: val_accuracy improved from 0.34359 to 0.40000, saving model to best_model.keras\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 1s/step - accuracy: 0.3112 - loss: 1.6725 - val_accuracy: 0.4000 - val_loss: 1.6461\n",
      "Epoch 7/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3072 - loss: 1.6595\n",
      "Epoch 7: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.3072 - loss: 1.6595 - val_accuracy: 0.3282 - val_loss: 1.6351\n",
      "Epoch 8/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3155 - loss: 1.6725\n",
      "Epoch 8: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 1s/step - accuracy: 0.3155 - loss: 1.6724 - val_accuracy: 0.3282 - val_loss: 1.6567\n",
      "Epoch 9/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3010 - loss: 1.6652\n",
      "Epoch 9: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.3010 - loss: 1.6652 - val_accuracy: 0.3744 - val_loss: 1.6258\n",
      "Epoch 10/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3054 - loss: 1.6485\n",
      "Epoch 10: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.3054 - loss: 1.6485 - val_accuracy: 0.3282 - val_loss: 1.6389\n",
      "Epoch 11/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3154 - loss: 1.6402\n",
      "Epoch 11: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1s/step - accuracy: 0.3153 - loss: 1.6402 - val_accuracy: 0.3795 - val_loss: 1.6313\n",
      "Epoch 12/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3039 - loss: 1.6469\n",
      "Epoch 12: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - accuracy: 0.3040 - loss: 1.6469 - val_accuracy: 0.3846 - val_loss: 1.6281\n",
      "Epoch 13/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3243 - loss: 1.6353\n",
      "Epoch 13: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 1s/step - accuracy: 0.3243 - loss: 1.6352 - val_accuracy: 0.3538 - val_loss: 1.6177\n",
      "Epoch 14/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3289 - loss: 1.6169\n",
      "Epoch 14: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 1s/step - accuracy: 0.3289 - loss: 1.6169 - val_accuracy: 0.3487 - val_loss: 1.6425\n",
      "Epoch 15/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3142 - loss: 1.6220\n",
      "Epoch 15: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.3142 - loss: 1.6220 - val_accuracy: 0.3590 - val_loss: 1.6153\n",
      "Epoch 16/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3336 - loss: 1.6124\n",
      "Epoch 16: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 1s/step - accuracy: 0.3336 - loss: 1.6125 - val_accuracy: 0.3333 - val_loss: 1.6183\n",
      "Epoch 17/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3227 - loss: 1.6140\n",
      "Epoch 17: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 1s/step - accuracy: 0.3227 - loss: 1.6140 - val_accuracy: 0.3744 - val_loss: 1.6311\n",
      "Epoch 18/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3258 - loss: 1.6257\n",
      "Epoch 18: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.3258 - loss: 1.6257 - val_accuracy: 0.3590 - val_loss: 1.6320\n",
      "Epoch 19/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3258 - loss: 1.6136\n",
      "Epoch 19: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 1s/step - accuracy: 0.3258 - loss: 1.6136 - val_accuracy: 0.3590 - val_loss: 1.5916\n",
      "Epoch 20/20\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.3327 - loss: 1.6024 \n",
      "Epoch 20: val_accuracy did not improve from 0.40000\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3973s\u001b[0m 15s/step - accuracy: 0.3327 - loss: 1.6024 - val_accuracy: 0.3487 - val_loss: 1.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 training complete. Model saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'output_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 20\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# ResNet50 Model\n",
    "def create_resnet50_model():\n",
    "    resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = Flatten()(resnet50_base.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=resnet50_base.input, outputs=output)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in resnet50_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# Train ResNet50\n",
    "print(\"Training ResNet50 model...\")\n",
    "resnet50_model = create_resnet50_model()\n",
    "resnet50_history = resnet50_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Save the final ResNet50 model\n",
    "resnet50_model.save(\"resnet50_final_model_2.h5\")\n",
    "\n",
    "print(\"ResNet50 training complete. Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HDPE       0.26      0.65      0.37        52\n",
      "        LDPE       0.00      0.00      0.00        26\n",
      "         PET       0.23      0.24      0.23        46\n",
      "          PP       0.07      0.04      0.05        28\n",
      "          PS       0.00      0.00      0.00        22\n",
      "         PVC       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.24       195\n",
      "   macro avg       0.09      0.15      0.11       195\n",
      "weighted avg       0.13      0.24      0.16       195\n",
      "\n",
      "Model Accuracy: 23.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aishwarya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the best saved model\n",
    "model = load_model(\"resnet50_final_model_2.h5\")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
